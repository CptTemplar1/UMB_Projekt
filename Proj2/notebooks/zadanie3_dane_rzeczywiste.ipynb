{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93027e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "from data_generation import load_cicids_data\n",
    "from feature_engineering import clean_cicids_data, engineer_features_cicids, normalize_data\n",
    "from model_training import train_model, evaluate_model, analyze_errors_task3\n",
    "from visualization import plot_distributions, plot_confusion_matrix, plot_roc_curve, plot_betas, plot_correlation_matrix, plot_learning_curve_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b02ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Konfiguracja ścieżki\n",
    "DATA_DIR = os.path.join('..', 'data', 'CICIDS2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b326bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Wczytywanie danych\n",
    "try:\n",
    "    print(\"Wczytywanie surowych danych CICIDS2017...\")\n",
    "    df_raw = load_cicids_data(DATA_DIR, sample_size=50000)\n",
    "    print(f\"Wczytano {len(df_raw)} wierszy.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "    print(\"Upewnij się, że pliki CSV znajdują się w folderze data/CICIDS2017/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bdd3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Przetwarzanie i Inżynieria Cech\n",
    "print(\"Czyszczenie danych...\")\n",
    "df_clean = clean_cicids_data(df_raw)\n",
    "print(\"Tworzenie cech...\")\n",
    "X_df, y, labels_raw = engineer_features_cicids(df_clean)\n",
    "feature_names = X_df.columns.tolist()\n",
    "\n",
    "plot_correlation_matrix(X_df, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266421ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Podział na Train/Val/Test (60/20/20)\n",
    "X_train_val, X_test_raw, y_train_val, y_test = train_test_split(X_df.values, y.values, test_size=0.2, stratify=y, random_state=42)\n",
    "X_train_raw, X_val_raw, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, stratify=y_train_val, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cba556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Normalizacja\n",
    "X_train, X_test, X_val, scaler = normalize_data(X_train_raw, X_test_raw, X_val_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71c347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Trenowanie (Balanced)\n",
    "print(\"Trenowanie modelu (Balanced)...\")\n",
    "model = train_model(X_train, y_train, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe11b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Ewaluacja\n",
    "metrics, y_pred, y_prob = evaluate_model(model, X_test, y_test)\n",
    "print(f\"Accuracy:  {metrics['Accuracy']:.4f}\")\n",
    "print(f\"Recall:    {metrics['Recall']:.4f}\")\n",
    "print(f\"AUC:       {metrics['AUC']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f765b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Wizualizacja\n",
    "plot_confusion_matrix(y_test, y_pred)\n",
    "plot_roc_curve(metrics)\n",
    "plot_betas(model, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25572ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9b: Generowanie i rysowanie krzywej uczenia\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_sizes_pct = [0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "train_scores = []\n",
    "val_scores = []\n",
    "train_sizes_abs = []\n",
    "\n",
    "print(\"Generowanie krzywej uczenia...\")\n",
    "for pct in train_sizes_pct:\n",
    "    # Bierzemy podzbiór danych treningowych\n",
    "    n_samples = int(pct * len(X_train))\n",
    "    train_sizes_abs.append(n_samples)\n",
    "    \n",
    "    X_sub = X_train[:n_samples]\n",
    "    y_sub = y_train[:n_samples]\n",
    "    \n",
    "    # Trenujemy tymczasowy model\n",
    "    model_temp = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "    model_temp.fit(X_sub, y_sub)\n",
    "    \n",
    "    # Zapisujemy wyniki\n",
    "    train_scores.append(accuracy_score(y_sub, model_temp.predict(X_sub)))\n",
    "    val_scores.append(accuracy_score(y_val, model_temp.predict(X_val)))\n",
    "\n",
    "plot_learning_curve_manual(train_sizes_abs, train_scores, val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d593124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Analiza Błędów\n",
    "fn_samples, fp_samples, _, _ = analyze_errors_task3(X_test_raw, y_test, y_pred, y_prob, feature_names)\n",
    "\n",
    "print(\"\\nPrzykładowe False Negatives (Atak uznany za normę):\")\n",
    "display(fn_samples.head())\n",
    "\n",
    "print(\"\\nPrzykładowe False Positives (Norma uznana za atak):\")\n",
    "display(fp_samples.head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
